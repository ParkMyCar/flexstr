[top_comments]

Environment = """
Benchmarks were run on:

```bash
$ cargo +nightly version -v
cargo 1.61.0-nightly (65c8266 2022-03-09)
release: 1.61.0-nightly
commit-hash: 65c82664263feddc5fe2d424be0993c28d46377a
commit-date: 2022-03-09
host: x86_64-unknown-linux-gnu
libgit2: 1.4.1 (sys:0.14.1 vendored)
libcurl: 7.80.0-DEV (sys:0.4.51+curl-7.80.0 vendored ssl:OpenSSL/1.1.1m)
os: Pop!_OS 20.04 (focal) [64-bit]
```
"""

"Version Specific Notes" = """
* Version 0.8.0
    * There is a bug where it is not always aligned on machine word boundary and therefore had some performance inconsistency
* Version 0.8.1
    * Fixed the alignment issue
    * It was briefly released and then yanked due to the size of the enum growing to four machine words
* Version 0.9.0
    * The first release using a redesigned union instead of an enum
    * It is both correctly aligned and now back to three machine words in size
    * It renames `FlexStr` to `LocalStr` and `AFlexStr` to `SharedStr`
"""

#"Third Party Crates" = """
#I decided to include some popular 3rd party crates to include in the create/clone benchmarks. I try to be as fair as
#possible, but I'm obviously inherently biased and even the choice of tests is biased. I'm primarily doing this as yet
#another measuring stick on whether `FlexStr` is performing adequately or not (and now I see some places it is not).
#
#Here are the 3rd party crates and their versions under test:
#
#```
#compact_str v0.3.1
#flexstr v0.8.0
#kstring v1.0.6
#smartstring v1.0.0
#smol_str v0.1.21
#```
#
#"""

"Benchmark Pitfalls" = """
Microbenchmarks are difficult to perform accurately, but after much trial and error I do believe these to be mostly accurate.
Do take the results with a grain of salt, however. Most importantly, we are looking for performance trends - this is what
you can expect to see in the results:

* At size 0, we would expect "empty string" detection to kick in - should be as fast as a constant more or less
* For literal tests, we are just testing how fast we can return the item - all work done at compile time
* For sizes 22 and under (on 64-bit), these are all inlined - we would expect these to be much faster than heap allocations
* For static and inlining, there are zero code differences between `LocalStr` and `SharedStr` and we shouldn't expect any
performance difference at all
"""

[table_comments]
#create_and_destroy_-_literal = """
#This just demonstrates the benefits of having a constant vs. heap allocating the constant as `String` is forced to do
#"""

create_and_destroy_-_computed = """
* All times represent the time spent to perform 10,000 iterations
* String sizes of 0 are just empty string constants, so we are able to match `String` on 0.8.1 and 0.9.0
* String sizes of 10 and 20 are triggering inlining, and 0.8.1 and 0.9.0 are getting a 1.5x to 2x speedup over `String`
* A slight bit slower than `String` on regular sized heap allocations (10-15%)
* For very large Strings, however, we are approximately 30% faster than `String`
"""

#clone_-_literal = """
#This again just demonstrates the benefits of having a constant vs. heap allocating the constant as `String` is forced to do.
#`AFlexStr` being much slower here is likely not correct in the real world as the code is identical to `FlexStr`
#"""

"clone_-_computed" = """
* All times represent the time spent to perform 10,000 iterations
* Empty string detection does not seem to trigger on clone for `String` and we handily beat it (2 - 4x faster)
* Cloning small strings is like a rocket in version 0.8.1 and 0.9.0 (15x faster than `String`!)
* `LocalStr` clones are very fast typically 10x faster or more than `String`, and 100-200x faster for huge strings
* `SharedStr` is still very fast, but 2.5x slower (uncontended) than `LocalStr` due to the need for atomic ref count.
It is still 3-5x faster than `String`, however
"""

#convert = """
#Thanks mostly to `ryu` and `itoa`, our primitive conversions handily outperforms `String`
#"""
